# Pre-training Llama2-7b from Scratch 

## Requirements
μ•„λμ ν¨ν‚¤μ§€λ¥Ό `pip install`λ¥Ό μ΄μ©ν•΄μ„ μ„¤μΉν•λ‹¤.

    deepspeed
    transformers
    accelerate
    datsets
    nvidia-ml-py3
    jsonlines

`mpi4py`λ” `sudo apt install` μ»¤λ§¨λ“λ¥Ό μ‚¬μ©ν•λ‹¤.

    sudo apt install python3-mpi4py


<br>


## π How to Start Pre-train Llama2-7b
Llama2 7b λ¨λΈμ„ μμ–΄λ‰΄μ¤ λ°μ΄ν„°λ΅ ZeRO-3λ¥Ό μ΄μ©ν•΄μ„ multi-gpuλ΅ μ‚¬μ „ν•™μµμ‹ν‚¤λ” μ½”λ“μ…λ‹λ‹¤.

    deepspeed --num_gpus={μ‚¬μ©ν•  GPU κ°μ} pretrain.py

<br>

- `--num_gpus`λ¥Ό μ§€μ •ν•μ§€ μ•μΌλ©΄ μ‚¬μ©κ°€λ¥ν• λ¨λ“  gpuλ¥Ό μ‚¬μ©ν•κ² λ©λ‹λ‹¤.
    ``````
    deepspeed pretrain.py
- ν•΄λ‹Ή μ½”λ“λ¥Ό μ‹¤ν–‰ν•κΈ° μ „ [κ²°κ³Όκ°€ μ €μ¥λ  λ΅μ»¬κ²½λ΅](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/pretrain.py#L55)(`output_dir`), [Deepspeed config νμΌ κ²½λ΅](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/pretrain.py#L58C1-L58C22)(`deepspeed_config_path`), [ν—κΉ…νμ΄μ¤ λ¦¬ν¬μ§€ν† λ¦¬](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/pretrain.py#L89)(`hub_model_id`) λ“±μ„ λ³ΈμΈμ ν™κ²½μ— λ§κ² μ•λ§κ² μ„¤μ •ν•μ„Έμ”.
- ν›λ ¨κ³Ό κ΄€λ ¨λ ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •μ€ [μ—¬κΈ°μ„](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/pretrain.py#L59) μμ •ν•  μ μμµλ‹λ‹¤.
    - κ° νλΌλ―Έν„°μ— λ€ν• μμ„Έν• μ„¤λ…μ€ [μ—¬κΈ°μ„](https://huggingface.co/docs/transformers/v4.35.2/en/main_classes/trainer#transformers.TrainingArguments) ν™•μΈν•  μ μμµλ‹λ‹¤.
- ZeRO-3μ™€ κ΄€λ ¨λ DeepSpeed μ„¤μ •μ€ [μ—¬κΈ°μ„](https://github.com/SEUNKOREA/Llama2_PT/blob/main/ds_config.json) μμ •ν•  μ μμµλ‹λ‹¤.
    - κ° μ„¤μ •μ— λ€ν• μμ„Έν• μ„¤λ…μ€ [μ—¬κΈ°μ„](https://www.deepspeed.ai/docs/config-json/) ν™•μΈν•  μ μμµλ‹λ‹¤.
- ν•΄λ‹Ή [μ½”λ“](https://github.com/SEUNKOREA/Llama2_PT/blob/main/pretrain.py)μ—μ„λ” [λ―Έλ¦¬ ν† ν¬λ‚μ΄μ§•λ μ²­ν¬μ‚¬μ΄μ¦λ¥Ό 4096μΌλ΅ ν† ν¬λ‚μ΄μ§•ν• μμ–΄λ‰΄μ¤ λ°μ΄ν„°](https://huggingface.co/datasets/leeseeun/tokenized_news_2gb_4096)λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. 
    - λ©”λ¨λ¦¬ λ¬Έμ  λ“± λ‹¤λ¥Έ μ΄μ λ΅ μ²­ν¬μ‚¬μ΄μ¦λ¥Ό λ‹¤λ¥΄κ² ν•μ—¬ λ°μ΄ν„°λ¥Ό ν† ν¬λ‚μ΄μ§• ν•κ³  μ‹¶μ€ κ²½μ°, [μ΄ λ¶€λ¶„](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/pretrain.py#L32C1-L32C1)μ μ£Όμ„μ„ ν•΄μ ν•κ³  `max_length`λ¥Ό μ›ν•λ” μ²­ν¬μ‚¬μ΄μ¦λ΅ λ°”κΏ”μ„ μ‹¤ν–‰ν•μ„Έμ”.
    - `max_length`λ” λ°μ΄ν„°λ¥Ό λ¨λΈμ— μ–΄λ–¤ μ²­ν¬μ‚¬μ΄μ¦λ΅ μλ¬μ„ λ„£μ„μ§€λ¥Ό μλ―Έν•λ©° Metaμ Llama2 λ¨λΈμ—μ„λ” 4,096μ„ μ‚¬μ©ν•μ€μµλ‹λ‹¤.
    - μ›λ³Έ λ°μ΄ν„°μ μ‚¬μ΄μ¦κ°€ ν° κ²½μ°, ν† ν¬λ‚μ΄μ§• κ³Όμ •μ— λ§μ€ μ‹κ°„μ΄ μ†μ”λ  μ μμµλ‹λ‹¤. μ΄λ° κ²½μ° λ―Έλ¦¬ νΉμ • μ²­ν¬μ‚¬μ΄μ¦μ ν¬κΈ°λ΅ ν† ν¬λ‚μ΄μ§•μ„ μ§„ν–‰ν• ν›„μ— ν—λΈμ— ν•΄λ‹Ή λ°μ΄ν„°μ…‹μ„ μ—…λ΅λ“ ν›„ λ¶λ¬μ™€μ„ μ‚¬μ©ν•λ” λ°©λ²•μ„ μ¶”μ²ν•©λ‹λ‹¤. ν•΄λ‹Ή λ°©λ²•μ€ μ•„λμ ["Tokenize Dataset"](https://github.com/SEUNKOREA/Llama2_PT/tree/main#-tokenize-dataset) κ°€μ΄λ“μ—μ„ ν™•μΈν•  μ μμµλ‹λ‹¤.

<br>
<br>

## π Generate Sentences
μ‚¬μ „ν•™μµλ Llama2-7b λ¨λΈμ„ λ°”νƒ•μΌλ΅ "I wanna go"μ λ’· λ¬Έμ¥μ„ μƒμ„±ν•λ” μ½”λ“μ…λ‹λ‹¤.

    python3 generate.py

<br>

- ν•΄λ‹Ή μ½”λ“λ¥Ό μ‹¤ν–‰ν•κΈ° μ „ [μ‚¬μ „ν•™μµλ λ¨λΈμ μ²΄ν¬ν¬μΈνΈκ°€ μ €μ¥λ κ²½λ΅](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/generate.py#L16)κ°€ μ¬λ°”λ¥Έμ§€ ν™•μΈν•μ„Έμ”.
- "I wanna go"λΏλ§ μ•„λ‹λΌ λ‹¤λ¥Έ λ¬Έμ¥μΌλ΅λ„ generationμ„ ν•κ³  μ‹¶μ€ κ²½μ° [ν•΄λ‹Ή λ¶€λ¶„](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/generate.py#L22C1-L22C1)μ— λ‹¤λ¥Έ λ¬Έμ¥μ„ μ¶”κ°€ν•λ©΄ λ©λ‹λ‹¤.

<br>

## π”¥ Tokenize Dataset

    python3 preprocess.py

<br>

- λ°μ΄ν„°λ¥Ό μ§μ ‘ ν† ν¬λ‚μ΄μ§•ν•κ³  μ‹¶μ€ κ²½μ°, ν•΄λ‹Ή κ°€μ΄λ“λ¥Ό μ°Έκ³ ν•μ„Έμ”.
- ν•΄λ‹Ή μ½”λ“λ” [(μ£Ό)λ”¥λ΅λ”©](https://www.deeploading.com/)μΌλ΅λ¶€ν„° μ κ³µλ°›μ€ μμ–΄λ‰΄μ¤ λ°μ΄ν„°(news_data_en.jsonl)λ¥Ό μ΄μ©ν•΄μ„ λ°μ΄ν„°λ¥Ό μ „μ²λ¦¬ν•κ³  μ²­ν¬μ‚¬μ΄μ¦λ¥Ό μ§€μ •ν•΄μ„ ν•΄λ‹Ή μ²­ν¬μ‚¬μ΄μ¦λ¥Ό κΈ°μ¤€μΌλ΅ ν† ν¬λ‚μ΄μ§•μ„ μ§„ν–‰ν•λ” μ½”λ“μ…λ‹λ‹¤. 
    - ν•΄λ‹Ή λ°μ΄ν„°λ” μ•„λμ™€ κ°™μ€ ν•μ‹μ…λ‹λ‹¤.
    ``````
    {"text": "(CNN)Share, and your gift will be multiplied. That may sound like an esoteric adage, but when Zully Broussard selflessly decided to give one of her kidneys to a stranger, her generosity paired up with big data. It resulted in six patients receiving transplants. That surprised and wowed her. \"I thought I was going to help this one person who I don't know, but the fact that so many people can have a life extension, that's pretty big,\" Broussard told CNN affiliate KGO. She may feel guided in her generosity by a higher power. \"Thanks for all the support and prayers,\" a comment on a Facebook page in her name read. ...μƒλµ... "}

- λ‹¤λ¥Έ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•κ³  μ‹¶μ€ κ²½μ°μ—λ„ ν•΄λ‹Ή μ½”λ“λ¥Ό μ‚¬μ©ν•  μ μμ§€λ§ μ½”λ“μ— μΌλ¶€ μμ •μ΄ ν•„μ”ν•  μ μμµλ‹λ‹¤.
- ν•΄λ‹Ή μ½”λ“λ¥Ό μ‹¤ν–‰ν•κΈ° μ „ [μ›λ³Έ λ°μ΄ν„°μ…‹ κ²½λ΅](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/preprocess.py#L55)μ™€ [μ²­ν¬ μ‚¬μ΄μ¦](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/preprocess.py#L62), [ν—κΉ…νμ΄μ¤ λ ν¬μ§€ν† λ¦¬](https://github.com/SEUNKOREA/Llama2_PT/blob/85bca4868bfbf81864c9ea9df0854281f63ac794/preprocess.py#L66)λ¥Ό μ¬λ°”λ¥΄κ² μ„¤μ •ν–λ”μ§€ ν™•μΈν•μ„Έμ”.

<br>

## π§© CPU offload
- `CUDA Out Of Memory` λ¬Έμ κ°€ λ°μƒν• κ²½μ°, CPU offloadλ¥Ό μ‚¬μ©ν•μ—¬ ν•΄κ²°ν•  μ μμµλ‹λ‹¤.
- [ν•΄λ‹Ή νμΌ](https://github.com/SEUNKOREA/Llama2_PT/blob/main/ds_config.json)μ— λ‹¤μκ³Ό κ°™μ΄ *β€offload_optimizerβ€, β€offload_paramβ€* μ„ μ¶”κ°€ν•λ©΄ λ©λ‹λ‹¤.
    ``````
    {
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu"
        },
        "offload_param":{
            "device": "cpu"
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
    ...μƒλµ...
- λ‹¨, μ΄ μ‘μ—…μ„ μν–‰ν•  κ²½μ° μ‚¬μ „ν•™μµμ— μ¤λ μ‹κ°„μ΄ μ†μ”λ  μ μμµλ‹λ‹¤. 

<br>

## Acknowlegemnets
ν•΄λ‹Ή μ½”λ“λ¥Ό ν…μ¤νΈν•κ³  μ‹¤ν–‰ν•¨μ— μμ–΄μ„ [(μ£Ό)λ”¥λ΅λ”©](https://www.deeploading.com/)μΌλ΅λ¶€ν„° μ„λ²„λ¥Ό μ§€μ›λ°›μ•μµλ‹λ‹¤.
<br>
μ μ©ν• μ§€μ›μ„ ν•΄μ£Όμ‹  [(μ£Ό)λ”¥λ΅λ”©](https://www.deeploading.com/)μ— κ°μ‚¬μ μΈμ‚¬λ¥Ό μ „ν•©λ‹λ‹¤.
